
GenAI

Verse 1:
How many rules must we write by hand
Before we learn that language isn't planned?
How many n-grams must we count and see
Before we understand probability?
How many times must we smooth the data
Before we see the patterns that we gather?
The answer, my friend, is learning from data
The answer is learning from data

Verse 2:
How many linear models must we train
Before we see the patterns in the rain?
How many gradients must we compute
Before the neural networks start to root?
How many layers must we stack up high
Before we reach the sky?
The answer, my friend, is backpropagation
The answer is backpropagation

Verse 3:
How many words must we embed in space
Before we capture meaning in their place?
How many sequences must we process through
Before the RNNs know what to do?
How many attention weights must we learn
Before the transformers start to turn?
The answer, my friend, is self-attention
The answer is self-attention

Verse 4:
How many images must we generate
Before we see the patterns that create?
How many GANs must fight and train
Before we get results without the pain?
How many diffusion steps must we take
Before the images start to make?
The answer, my friend, is gradual denoising
The answer is gradual denoising

Verse 5:
How many modalities must we align
Before the AI starts to truly shine?
How many human preferences must we learn
Before the models start to turn?
How many reasoning steps must we trace
Before the AI shows its grace?
The answer, my friend, is reinforcement learning
The answer is reinforcement learning

Final Chorus:
The answer, my friend, is building from scratch
The answer is building from scratch
From probability to modern AI
The journey never ends, it's just begun
The answer is building from scratch